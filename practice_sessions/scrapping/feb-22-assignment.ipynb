{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to this given URL and solve the following questions\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=LuTONVLzESM',\n",
       " 'https://www.youtube.com/watch?v=KWXKegvNa-I',\n",
       " 'https://www.youtube.com/watch?v=dArUpCasmnE',\n",
       " 'https://www.youtube.com/watch?v=HqG2QchBw8Y',\n",
       " 'https://www.youtube.com/watch?v=1izKrQHyx9M']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "\n",
    "def get_video_url():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    driver.get(base_url)\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"thumbnail\")))\n",
    "\n",
    "    video_url = driver.find_elements(\n",
    "        By.XPATH, '//*[@id=\"thumbnail\"]')\n",
    "\n",
    "    video_url_list = []\n",
    "    for url in video_url:\n",
    "        # print(url.get_attribute(\"href\"))\n",
    "        video_url_list.append(url.get_attribute(\"href\"))\n",
    "\n",
    "    # print(len(video_url_list))\n",
    "    video_url_list = list(filter(None, video_url_list))\n",
    "    video_url_list2 = list(set(video_url_list))\n",
    "    video_url_list2.sort(key=video_url_list.index)\n",
    "\n",
    "    \"\"\" for i in range(5):\n",
    "        print(video_url_list2[i]) \"\"\"\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return video_url_list2[0:5]\n",
    "\n",
    "\n",
    "get_video_url()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://i.ytimg.com/vi/LuTONVLzESM/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCaMVZmPmUqryYudQm6lobkny_-Cg',\n",
       " 'https://i.ytimg.com/vi/KWXKegvNa-I/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLAZ9XEzNrcu4YfUzbEfohE3CdXIVw',\n",
       " 'https://i.ytimg.com/vi/dArUpCasmnE/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCdiUURSFwzHKBaqzNQnNYVFf1PZA',\n",
       " 'https://i.ytimg.com/vi/HqG2QchBw8Y/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLB2qRg5GsfQROPt6YiiG3CXXiExjg',\n",
       " 'https://i.ytimg.com/vi/1izKrQHyx9M/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCvjSUCwD4j5ZVE_nUMLg6QNCpkfg']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "\n",
    "def get_video_thumbnail():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(20)\n",
    "\n",
    "    driver.get(base_url)\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"thumbnail\")))\n",
    "\n",
    "    thumbnails = driver.find_elements(\n",
    "        By.XPATH, '//*[@id=\"thumbnail\"]/yt-image/img')\n",
    "\n",
    "    thumbnail_url_list = []\n",
    "    for url in thumbnails:\n",
    "        # print(url.get_attribute(\"href\"))\n",
    "        thumbnail_url_list.append(url.get_attribute(\"src\"))\n",
    "\n",
    "    # print(len(thumbnail_url_list))\n",
    "    thumbnail_url_list = list(filter(None, thumbnail_url_list))\n",
    "    thumbnail_url_list2 = list(set(thumbnail_url_list))\n",
    "    thumbnail_url_list2.sort(key=thumbnail_url_list.index)\n",
    "\n",
    "    \"\"\" for i in range(5):\n",
    "        print(thumbnail_url_list2[i]) \"\"\"\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return thumbnail_url_list2[0:5]\n",
    "\n",
    "\n",
    "get_video_thumbnail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Write a python program to extract the title of the first five videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARTS ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä PAHAL üî• || Launching Class 11th ARTS BATCH',\n",
       " 'Something Big Coming Soon For Class - 9th & 10th Students üî• || Stay Tuned For More Updates üñãÔ∏è',\n",
       " 'Launching PAHAL Batch üî• For Class 11th Arts Students üí™',\n",
       " 'Launching FUNDO For Class - 6th to 8th Students üî•üíØ || Ab Hoga Padhai Ke Sath FUN ü§©',\n",
       " '‚ö°Unleashing the Power of PW Internationally‚ö°| Launching Physics Wallah Gulf']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "\n",
    "def get_video_title():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    driver.get(base_url)\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"thumbnail\")))\n",
    "\n",
    "    titles = driver.find_elements(\n",
    "        By.XPATH, '//*[@id=\"video-title\"]')\n",
    "\n",
    "    titles_list = []\n",
    "    for title in titles:\n",
    "        titles_list.append(title.text)\n",
    "\n",
    "    # print(len(titles_list))\n",
    "    titles_list = list(filter(None, titles_list))\n",
    "    titles_list2 = list(set(titles_list))\n",
    "    titles_list2.sort(key=titles_list.index)\n",
    "\n",
    "    \"\"\" for i in range(5):\n",
    "        print(titles_list2[i]) \"\"\"\n",
    "\n",
    "    driver.quit()\n",
    "    return titles_list2[0:5]\n",
    "\n",
    "\n",
    "get_video_title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Write a python program to extract the number of views of the first five videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15K views', '39K views', '32K views', '26K views', '70K views']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "\n",
    "def get_views():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    driver.get(base_url)\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"thumbnail\")))\n",
    "\n",
    "    views = driver.find_elements(\n",
    "        By.XPATH, '//*[@id=\"metadata\"]/div/span')\n",
    "\n",
    "    views_list = []\n",
    "    for view in views:\n",
    "        if (view.text.__contains__(\"views\")):\n",
    "            views_list.append(view.text)\n",
    "\n",
    "    # print(len(titles_list))\n",
    "    views_list = list(filter(None, views_list))\n",
    "    views_list2 = list(set(views_list))\n",
    "    views_list2.sort(key=views_list.index)\n",
    "\n",
    "    \"\"\" for i in range(5):\n",
    "        print(views_list2[i]) \"\"\"\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return views_list2[0:5]\n",
    "\n",
    "\n",
    "get_views()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Write a python program to extract the time of posting of video for the first five videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 days ago', '2 weeks ago', '3 weeks ago', '1 month ago', '2 months ago']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "\n",
    "def get_time():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    driver.get(base_url)\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"thumbnail\")))\n",
    "\n",
    "    times = driver.find_elements(\n",
    "        By.XPATH, '//*[@id=\"metadata\"]/div/span')\n",
    "\n",
    "    times_list = []\n",
    "    for time in times:\n",
    "        if (time.text.__contains__(\"ago\")):\n",
    "            times_list.append(time.text)\n",
    "\n",
    "    # print(len(titles_list))\n",
    "    times_list = list(filter(None, times_list))\n",
    "    times_list2 = list(set(times_list))\n",
    "    times_list2.sort(key=times_list.index)\n",
    "\n",
    "    \"\"\" for i in range(5):\n",
    "        print(times_list2[i]) \"\"\"\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return times_list2[0:5]\n",
    "\n",
    "    # Saving Scrapped data in CSV file\n",
    "\n",
    "\n",
    "get_time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Save all the data scraped in the above questions in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "video_url = get_video_url()\n",
    "video_thumbnail = get_video_thumbnail()\n",
    "video_title = get_video_title()\n",
    "video_views = get_views()\n",
    "video_time = get_time()\n",
    "\n",
    "\n",
    "column_dict = {\"Video URL\": video_url, \"Video Thumbnail\": video_thumbnail,\n",
    "               \"Video Title\": video_title, \"Video Views\": video_views, \"Video Time\": video_time}\n",
    "\n",
    "df = pd.DataFrame(column_dict)\n",
    "df.to_csv('PW_Youtube_Scrapped_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
